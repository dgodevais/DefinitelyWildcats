{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "from scipy import sparse as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, log_loss, confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyspark related imports\n",
    "import time\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.mllib.linalg import Matrices\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Python Spark SQL basic example2\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlCtx = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://hln240/sparce_matrices_imdb_1/21_output_file_imdb_1.npz to sparce_matrices_imdb_1/21_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/11_output_file_imdb_1.npz to sparce_matrices_imdb_1/11_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/15_output_file_imdb_1.npz to sparce_matrices_imdb_1/15_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/17_output_file_imdb_1.npz to sparce_matrices_imdb_1/17_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/16_output_file_imdb_1.npz to sparce_matrices_imdb_1/16_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/19_output_file_imdb_1.npz to sparce_matrices_imdb_1/19_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/10_output_file_imdb_1.npz to sparce_matrices_imdb_1/10_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/14_output_file_imdb_1.npz to sparce_matrices_imdb_1/14_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/13_output_file_imdb_1.npz to sparce_matrices_imdb_1/13_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/1_output_file_imdb_1.npz to sparce_matrices_imdb_1/1_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/12_output_file_imdb_1.npz to sparce_matrices_imdb_1/12_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/20_output_file_imdb_1.npz to sparce_matrices_imdb_1/20_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/18_output_file_imdb_1.npz to sparce_matrices_imdb_1/18_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/26_output_file_imdb_1.npz to sparce_matrices_imdb_1/26_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/24_output_file_imdb_1.npz to sparce_matrices_imdb_1/24_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/29_output_file_imdb_1.npz to sparce_matrices_imdb_1/29_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/23_output_file_imdb_1.npz to sparce_matrices_imdb_1/23_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/22_output_file_imdb_1.npz to sparce_matrices_imdb_1/22_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/2_output_file_imdb_1.npz to sparce_matrices_imdb_1/2_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/28_output_file_imdb_1.npz to sparce_matrices_imdb_1/28_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/31_output_file_imdb_1.npz to sparce_matrices_imdb_1/31_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/27_output_file_imdb_1.npz to sparce_matrices_imdb_1/27_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/30_output_file_imdb_1.npz to sparce_matrices_imdb_1/30_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/25_output_file_imdb_1.npz to sparce_matrices_imdb_1/25_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/9_output_file_imdb_1.npz to sparce_matrices_imdb_1/9_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/4_output_file_imdb_1.npz to sparce_matrices_imdb_1/4_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/3_output_file_imdb_1.npz to sparce_matrices_imdb_1/3_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/6_output_file_imdb_1.npz to sparce_matrices_imdb_1/6_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/7_output_file_imdb_1.npz to sparce_matrices_imdb_1/7_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/8_output_file_imdb_1.npz to sparce_matrices_imdb_1/8_output_file_imdb_1.npz\n",
      "download: s3://hln240/sparce_matrices_imdb_1/5_output_file_imdb_1.npz to sparce_matrices_imdb_1/5_output_file_imdb_1.npz\n"
     ]
    }
   ],
   "source": [
    "import awscli\n",
    "\n",
    "!aws s3 cp s3://hln240/sparce_matrices_imdb_1/ sparce_matrices_imdb_1/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAFOLDER = \"sparce_matrices_imdb_1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30867, 90003)\n"
     ]
    }
   ],
   "source": [
    "# Load the sparse matrices containing the image feature data\n",
    "sp_face_features = None\n",
    "first = True\n",
    "for filename in os.listdir(DATAFOLDER):\n",
    "    fn_path = os.path.join(DATAFOLDER + filename)\n",
    "    b = np.load(fn_path)\n",
    "    data = b['data']\n",
    "    m_format = b['format']\n",
    "    shape = b['shape']\n",
    "    row = b['row']\n",
    "    col = b['col']\n",
    "    tmp = sp.csr_matrix( (data,(row,col)), shape=shape )\n",
    "    if first:\n",
    "        sp_face_features = sp.vstack((tmp,sp_face_features), format=\"csr\")\n",
    "    else:\n",
    "        sp_face_features = tmp\n",
    "        first = False\n",
    "print(sp_face_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spark_gender_dataframe_from_image_matrix(image_matrix):\n",
    "    \"\"\"\n",
    "    Process the sparse scipy matrix with image features and return a spark dataframe with sparse vectors\n",
    "    \"\"\"\n",
    "    VECTOR_LENGTH = 90000\n",
    "    spark_rows_formatted = []\n",
    "    skip_count = 0\n",
    "    for i, row in enumerate(image_matrix):\n",
    "        active_cols = row.nonzero()[1]\n",
    "        if active_cols[0] == 0:\n",
    "            active_cols = active_cols[1:-2]\n",
    "        else:\n",
    "            active_cols = active_cols[:-2]\n",
    "        indexes = list(map(lambda x: (x, 1), active_cols))\n",
    "        try:\n",
    "            gender = int(image_matrix[i,90002])\n",
    "            spark_rows_formatted.append( (gender, indexes) )\n",
    "        except ValueError:\n",
    "            skip_count += 1\n",
    "    print(\"Note that {} images were skipped due to nan label.\".format(str(skip_count)))\n",
    "    mapped_f = map(lambda x: (x[0], Vectors.sparse(VECTOR_LENGTH, x[1][1:])), spark_rows_formatted)\n",
    "    df_gender_analysis = spark.createDataFrame(mapped_f, schema=[\"label\", \"features\"])\n",
    "    return df_gender_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that 598 images were skipped due to nan label.\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|(90000,[3502,4802...|\n",
      "|    0|(90000,[2403,3391...|\n",
      "|    0|(90000,[2190,3304...|\n",
      "|    1|(90000,[4018,5119...|\n",
      "|    1|(90000,[3994,4404...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_gender_analysis  = get_spark_gender_dataframe_from_image_matrix(sp_face_features)\n",
    "df_gender_analysis.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data has 22763 instances.\n",
      "The test data has 7506 instances.\n"
     ]
    }
   ],
   "source": [
    "# Prepare the training and test data\n",
    "splits = df_gender_analysis.randomSplit([0.75, 0.25])\n",
    "data_train = splits[0]\n",
    "data_test = splits[1]\n",
    "print(\"The training data has {} instances.\".format(data_train.count()))\n",
    "print(\"The test data has {} instances.\".format(data_test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|                 FPR|                TPR|\n",
      "+--------------------+-------------------+\n",
      "|                 0.0|                0.0|\n",
      "|                 0.0|0.01722466631869361|\n",
      "|                 0.0| 0.0345238982924465|\n",
      "|                 0.0|0.05174856461114011|\n",
      "|                 0.0|0.06912236223995227|\n",
      "|                 0.0|0.08619789724852733|\n",
      "|                 0.0|0.10334799791216166|\n",
      "|                 0.0|0.12072179554097383|\n",
      "|                 0.0|0.12243680560733726|\n",
      "|                 0.0|0.14003430020132726|\n",
      "|                 0.0|0.15688613824472447|\n",
      "|                 0.0|0.17425993587353664|\n",
      "| 1.06928999144568E-4| 0.1913354708821117|\n",
      "| 1.06928999144568E-4|0.20848557154574604|\n",
      "| 1.06928999144568E-4|0.22563567220938036|\n",
      "| 1.06928999144568E-4|0.24300946983819252|\n",
      "| 1.06928999144568E-4|0.24703601521139362|\n",
      "|3.207869974337040...| 0.2640369845649094|\n",
      "|3.207869974337040...| 0.2810379539184252|\n",
      "| 4.27715996578272E-4| 0.2984863172022966|\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "areaUnderROC: 0.9693236560210428\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(data_train)\n",
    "trainingSummary = lrModel.summary\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6182097023165007"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lrModel.transform(data_test)\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

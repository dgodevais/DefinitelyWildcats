{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Facial Features For Gender Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, log_loss, confusion_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "DATAFOLDER = \"/Users/snuffles753/Documents/NYU-GSAS/ds1004/term-project/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pyspark related imports\n",
    "import time\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.mllib.linalg import Matrices\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Python Spark SQL basic example2\").getOrCreate()\n",
    "spark.conf.set(\"spark.executor.memory\", '8g')\n",
    "spark.conf.set('spark.executor.cores', '2')\n",
    "spark.conf.set('spark.cores.max', '2')\n",
    "spark.conf.set(\"spark.driver.memory\",'8g')\n",
    "sc = spark.sparkContext\n",
    "sqlCtx = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34917, 90003)\n"
     ]
    }
   ],
   "source": [
    "# Load the sparse matrices containing the image feature data\n",
    "sp_face_features = None\n",
    "first = True\n",
    "num_loaded = 0\n",
    "for filename in os.listdir(os.path.join(DATAFOLDER, 'sparse-images2/')):\n",
    "    fn_path = os.path.join(DATAFOLDER, 'sparse-images2/' + filename)\n",
    "    b = np.load(fn_path)\n",
    "    data = b['data']\n",
    "    m_format = b['format']\n",
    "    shape = b['shape']\n",
    "    row = b['row']\n",
    "    col = b['col']\n",
    "    tmp = sp.csr_matrix( (data,(row,col)), shape=shape )\n",
    "    if first:\n",
    "        sp_face_features = sp.vstack((tmp,sp_face_features), format=\"csr\")\n",
    "    else:\n",
    "        sp_face_features = tmp\n",
    "        first = False\n",
    "print(sp_face_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 90000\n",
    "GENDER_INDEX = NUM_FEATURES + 2\n",
    "AGE_INDEX = NUM_FEATURES + 1\n",
    "NUM_F_SETS = 9\n",
    "COLS_PER_SET = 10000\n",
    "PIC_DIM = 100\n",
    "FIRST_COL_OFFSET = 1\n",
    "NOSE_BRIDGE_INDEX = 3\n",
    "\n",
    "def get_x_y_coord(z):\n",
    "    z = z - FIRST_COL_OFFSET\n",
    "    x = (z - ((z // COLS_PER_SET) * COLS_PER_SET)) % PIC_DIM\n",
    "    y = (z - ((z // COLS_PER_SET) * COLS_PER_SET)) // PIC_DIM\n",
    "    feature_set = z // COLS_PER_SET\n",
    "    return (x, y, feature_set)\n",
    "        \n",
    "def get_distance_features(active_cols):\n",
    "    coords = list(map(lambda z: get_x_y_coord(z), active_cols))\n",
    "    np_coords = np.array(coords) \n",
    "    distances = []\n",
    "    nose_feature_set = np_coords[np_coords[:,2] == NOSE_BRIDGE_INDEX]       \n",
    "    for i in range(0, NUM_F_SETS):\n",
    "        feature_set = np_coords[np_coords[:,2] == i]\n",
    "        if i != 2:\n",
    "            if len(nose_feature_set) == 0 or len(feature_set) == 0:\n",
    "                distances.append( (NUM_FEATURES + i, 0) )\n",
    "            else:\n",
    "                nose_centroid = np.mean(nose_feature_set, axis=0)[0:2]\n",
    "                feature_centroid = np.mean(feature_set, axis=0)[0:2]\n",
    "                dist = np.linalg.norm(nose_centroid - feature_centroid)\n",
    "                distances.append( (NUM_FEATURES + i, dist) )\n",
    "    return distances\n",
    "\n",
    "def get_spark_gender_dataframe_from_image_matrix(image_matrix, label_index):\n",
    "    \"\"\"\n",
    "    Process the sparse scipy matrix with image features and return a spark dataframe with sparse vectors\n",
    "    \"\"\"\n",
    "    spark_rows_formatted = []\n",
    "    skip_count = 0\n",
    "    for i, row in enumerate(image_matrix):\n",
    "        active_cols = row.nonzero()[1]\n",
    "        # Remove first column if index col and remove last two label columns\n",
    "        if active_cols[0] == 0:\n",
    "            active_cols = active_cols[1:-2]\n",
    "        else:\n",
    "            active_cols = active_cols[:-2]\n",
    "        indexes = list(map(lambda z: (z, 1), active_cols))\n",
    "        indexes += get_distance_features(active_cols)\n",
    "        try:\n",
    "            label = int(image_matrix[i, label_index])\n",
    "            spark_rows_formatted.append( (label, indexes) )\n",
    "        except ValueError:\n",
    "            skip_count += 1\n",
    "    print(\"Note that {} images were skipped due to nan label.\".format(str(skip_count)))\n",
    "    mapped_f = map(lambda x: (x[0], Vectors.sparse(NUM_FEATURES + NUM_F_SETS, x[1][1:])), \n",
    "                   spark_rows_formatted)\n",
    "    df_analysis = spark.createDataFrame(mapped_f, schema=[\"label\", \"features\"])\n",
    "    return df_analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that 677 images were skipped due to nan label.\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    1|(90009,[3091,4001...|\n",
      "|    0|(90009,[2800,3401...|\n",
      "|    0|(90009,[4296,5393...|\n",
      "|    0|(90009,[3195,4105...|\n",
      "|    0|(90009,[2576,3678...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_gender_analysis = get_spark_gender_dataframe_from_image_matrix(sp_face_features,\n",
    "                                                                 GENDER_INDEX)\n",
    "df_gender_analysis.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data has 25708 instances.\n",
      "The test data has 8532 instances.\n"
     ]
    }
   ],
   "source": [
    "# Prepare the training and test data\n",
    "splits = df_gender_analysis.randomSplit([0.75, 0.25])\n",
    "data_train = splits[0]\n",
    "data_test = splits[1]\n",
    "print(\"The training data has {} instances.\".format(data_train.count()))\n",
    "print(\"The test data has {} instances.\".format(data_test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modeling with scikit\n",
    "model = LogisticRegression()\n",
    "model.fit(data_train, labels_train2)\n",
    "y_pred = model.predict_proba(data_test)[:, 1]\n",
    "accuracy = accuracy_score(labels_test2, (y_pred > 0.5).astype(int))\n",
    "logloss = log_loss(labels_test2, y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(labels_test2, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "metrics = {'Accuracy': accuracy, 'ROC AUC': roc_auc, 'Log Loss': logloss}\n",
    "plt.plot(fpr, tpr, label='AUC = {0:.3f}'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression (base case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|                 FPR|                TPR|\n",
      "+--------------------+-------------------+\n",
      "|                 0.0|                0.0|\n",
      "|                 0.0|0.01885020944677163|\n",
      "|                 0.0|0.03798931099234436|\n",
      "|                 0.0|0.05669507438971544|\n",
      "|                 0.0|0.07540083778708652|\n",
      "|                 0.0|0.09388993211035679|\n",
      "|                 0.0|0.11266791853242814|\n",
      "|                 0.0|0.13187924310270113|\n",
      "|                 0.0|0.15087389859887332|\n",
      "|                 0.0|0.16979633107034522|\n",
      "|8.430281571404485E-5|0.18857431749241657|\n",
      "|8.430281571404485E-5|0.20749674996388848|\n",
      "|8.430281571404485E-5|0.22656362848476094|\n",
      "|3.372112628561794E-4|0.24490827675863064|\n",
      "|3.372112628561794E-4|0.24519716885743176|\n",
      "|4.215140785702242E-4|0.26383070923010254|\n",
      "|5.058168942842691E-4| 0.2823920265780731|\n",
      "|6.744225257123588E-4|0.30124223602484473|\n",
      "|0.001095936604282583|0.31929799219991334|\n",
      "|0.001180239419996...|0.33778708652318357|\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "areaUnderROC: 0.959279237593732\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=.3)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(data_train)\n",
    "trainingSummary = lrModel.summary\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lrModel.transform(data_test)\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator.getMetricName()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that 0 images were skipped due to nan label.\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|(90009,[1811,2589...|\n",
      "|    1|(90009,[4801,5100...|\n",
      "|    1|(90009,[3313,4197...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fn_path = os.path.join(DATAFOLDER, '1_our_faces_sparse.npz')\n",
    "b = np.load(fn_path)\n",
    "data = b['data']\n",
    "m_format = b['format']\n",
    "shape = b['shape']\n",
    "row = b['row']\n",
    "col = b['col']\n",
    "sp_face_features_me = sp.csr_matrix( (data,(row,col)), shape=shape )\n",
    "df_age_analysis_me = get_spark_gender_dataframe_from_image_matrix(sp_face_features_me,\n",
    "                                                                 GENDER_INDEX)\n",
    "df_age_analysis_me.show(5)                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|    0|(90009,[1811,2589...|[-0.1088840082218...|[0.47280585982957...|       1.0|\n",
      "|    1|(90009,[4801,5100...|[-0.5003597348388...|[0.37745613350055...|       1.0|\n",
      "|    1|(90009,[3313,4197...|[0.03523766410104...|[0.50880850458927...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lrModel.transform(df_age_analysis_me)\n",
    "predictions.show()\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_analysis = get_spark_gender_dataframe_from_image_matrix(sp_face_features,\n",
    "                                                                 AGE_INDEX)\n",
    "df_age_analysis.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(maxIter=10, regParam=.3)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(df_age_analysis)\n",
    "# Print the coefficients and intercept for linear regression\n",
    "# print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
    "print(\"Intercept: %s\" % str(lrModel.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "trainingSummary = lrModel.summary\n",
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.show()\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1_our_faces_sparse.npz\n",
    "fn_path = os.path.join(DATAFOLDER, '1_our_faces_sparse.npz')\n",
    "b = np.load(fn_path)\n",
    "data = b['data']\n",
    "m_format = b['format']\n",
    "shape = b['shape']\n",
    "row = b['row']\n",
    "col = b['col']\n",
    "sp_face_features_me = sp.csr_matrix( (data,(row,col)), shape=shape ).todense()\n",
    "# df_age_analysis_me = get_spark_gender_dataframe_from_image_matrix(sp_face_features_me,\n",
    "#                                                                  AGE_INDEX)\n",
    "# df_age_analysis_me.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = lrModel.coefficients\n",
    "np_coefs = coefs.toArray()\n",
    "print(np_coefs[0:9000])\n",
    "features = sp_face_features_me[:,1:90001].T\n",
    "coefs_fmt = np_coefs[0:90000].reshape((1, -1)).T\n",
    "print(features)\n",
    "print(coefs_fmt)\n",
    "preds = features.T @ coefs_fmt\n",
    "# predictions = np.dot(coefs[0:90000], sp_face_features_me[:,1:90000])\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Multilayer Perceptron approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify layers for the neural network:\n",
    "# input layer of size 4 (features), two intermediate of size 5 and 4\n",
    "# and output of size 3 (classes)\n",
    "layers = [90000, 10, 10, 2]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "# train the model\n",
    "model = trainer.fit(data_train.limit(1000))\n",
    "\n",
    "# compute accuracy on the test set\n",
    "result = model.transform(data_test)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

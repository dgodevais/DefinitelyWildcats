{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Facial Features For Gender Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, log_loss, confusion_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "DATAFOLDER = \"/Users/snuffles753/Documents/NYU-GSAS/ds1004/term-project/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyspark related imports\n",
    "import time\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.mllib.linalg import Matrices\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Python Spark SQL basic example2\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlCtx = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 90003)\n"
     ]
    }
   ],
   "source": [
    "# Load the sparse matrices containing the image feature data\n",
    "sp_face_features = None\n",
    "first = True\n",
    "for filename in os.listdir(os.path.join(DATAFOLDER, 'sparse-images/')):\n",
    "    fn_path = os.path.join(DATAFOLDER, 'sparse-images/' + filename)\n",
    "    b = np.load(fn_path)\n",
    "    data = b['data']\n",
    "    m_format = b['format']\n",
    "    shape = b['shape']\n",
    "    row = b['row']\n",
    "    col = b['col']\n",
    "    tmp = sp.csr_matrix( (data,(row,col)), shape=shape )\n",
    "    if first:\n",
    "        sp_face_features = sp.vstack((tmp,sp_face_features), format=\"csr\")\n",
    "    else:\n",
    "        sp_face_features = tmp\n",
    "        first = False\n",
    "print(sp_face_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spark_gender_dataframe_from_image_matrix(image_matrix):\n",
    "    \"\"\"\n",
    "    Process the sparse scipy matrix with image features and return a spark dataframe with sparse vectors\n",
    "    \"\"\"\n",
    "    VECTOR_LENGTH = 90000\n",
    "    spark_rows_formatted = []\n",
    "    skip_count = 0\n",
    "    for i, row in enumerate(image_matrix):\n",
    "        active_cols = row.nonzero()[1]\n",
    "        if active_cols[0] == 0:\n",
    "            active_cols = active_cols[1:-2]\n",
    "        else:\n",
    "            active_cols = active_cols[:-2]\n",
    "        indexes = list(map(lambda x: (x, 1), active_cols))\n",
    "        try:\n",
    "            gender = int(image_matrix[i,90002])\n",
    "            spark_rows_formatted.append( (gender, indexes) )\n",
    "        except ValueError:\n",
    "            skip_count += 1\n",
    "    print(\"Note that {} images were skipped due to nan label.\".format(str(skip_count)))\n",
    "    mapped_f = map(lambda x: (x[0], Vectors.sparse(VECTOR_LENGTH, x[1][1:])), spark_rows_formatted)\n",
    "    df_gender_analysis = spark.createDataFrame(mapped_f, schema=[\"label\", \"features\"])\n",
    "    return df_gender_analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that 42 images were skipped due to nan label.\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    1|(90000,[4820,5922...|\n",
      "|    1|(90000,[4191,5390...|\n",
      "|    1|(90000,[3589,4591...|\n",
      "|    0|(90000,[4681,5679...|\n",
      "|    1|(90000,[4488,5488...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_gender_analysis = get_spark_gender_dataframe_from_image_matrix(sp_face_features)\n",
    "df_gender_analysis.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data has 2968 instances.\n",
      "The test data has 990 instances.\n"
     ]
    }
   ],
   "source": [
    "# Prepare the training and test data\n",
    "splits = df_gender_analysis.randomSplit([0.75, 0.25])\n",
    "data_train = splits[0]\n",
    "data_test = splits[1]\n",
    "print(\"The training data has {} instances.\".format(data_train.count()))\n",
    "print(\"The test data has {} instances.\".format(data_test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modeling with scikit\n",
    "model = LogisticRegression()\n",
    "model.fit(data_train, labels_train2)\n",
    "y_pred = model.predict_proba(data_test)[:, 1]\n",
    "accuracy = accuracy_score(labels_test2, (y_pred > 0.5).astype(int))\n",
    "logloss = log_loss(labels_test2, y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(labels_test2, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "metrics = {'Accuracy': accuracy, 'ROC AUC': roc_auc, 'Log Loss': logloss}\n",
    "plt.plot(fpr, tpr, label='AUC = {0:.3f}'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Multilayer Perceptron approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+\n",
      "|FPR|                TPR|\n",
      "+---+-------------------+\n",
      "|0.0|                0.0|\n",
      "|0.0|0.01684088269454123|\n",
      "|0.0|0.03368176538908246|\n",
      "|0.0|0.05110336817653891|\n",
      "|0.0|0.06794425087108014|\n",
      "|0.0|0.08478513356562137|\n",
      "|0.0| 0.1016260162601626|\n",
      "|0.0|0.11846689895470383|\n",
      "|0.0|0.13530778164924506|\n",
      "|0.0| 0.1521486643437863|\n",
      "|0.0|0.16898954703832753|\n",
      "|0.0|0.18583042973286876|\n",
      "|0.0|   0.20267131242741|\n",
      "|0.0|0.21951219512195122|\n",
      "|0.0|0.22067363530778164|\n",
      "|0.0|0.23809523809523808|\n",
      "|0.0|0.25551684088269455|\n",
      "|0.0|0.27235772357723576|\n",
      "|0.0|  0.289198606271777|\n",
      "|0.0| 0.3060394889663182|\n",
      "+---+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "areaUnderROC: 0.9999277595390034\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(data_train)\n",
    "trainingSummary = lrModel.summary\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5559371912279878"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lrModel.transform(data_test)\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'areaUnderROC'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.getMetricName()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
